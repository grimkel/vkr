{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcab390f-54c1-4c52-bd0b-5042676f1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 06:54:10.266484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 06:54:10.396666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-15 06:54:10.396685: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-15 06:54:11.014726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-15 06:54:11.014789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-15 06:54:11.014797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import auc, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d58f6b4-4ca6-4ad3-8f38-82554490b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUROCEarlyStoppingPruneCallback(Callback):\n",
    "    \"\"\"Stop training when a monitored quantity has stopped improving.\n",
    "    # Arguments\n",
    "        x_val:\n",
    "            Input vector of validation data.\n",
    "        y_val:\n",
    "            Labels for input vector of validation data.\n",
    "        trial:\n",
    "            A :class:`~optuna.trial.Trial` corresponding to the current evaluation of the\n",
    "            objective function.\n",
    "        min_delta: minimum change in the monitored quantity\n",
    "            to qualify as an improvement, i.e. an absolute\n",
    "            change of less than min_delta, will count as no\n",
    "            improvement.\n",
    "        patience: number of epochs that produced the monitored\n",
    "            quantity with no improvement after which training will\n",
    "            be stopped.\n",
    "            Validation quantities may not be produced for every\n",
    "            epoch, if the validation frequency\n",
    "            (`model.fit(validation_freq=5)`) is greater than one.\n",
    "        verbose: verbosity mode.\n",
    "        mode: one of {auto, min, max}. In `min` mode,\n",
    "            training will stop when the quantity\n",
    "            monitored has stopped decreasing; in `max`\n",
    "            mode it will stop when the quantity\n",
    "            monitored has stopped increasing; in `auto`\n",
    "            mode, the direction is automatically inferred\n",
    "            from the name of the monitored quantity.\n",
    "        baseline: Baseline value for the monitored quantity to reach.\n",
    "            Training will stop if the model doesn't show improvement\n",
    "            over the baseline.\n",
    "        restore_best_weights: whether to restore model weights from\n",
    "            the epoch with the best value of the monitored quantity.\n",
    "            If False, the model weights obtained at the last step of\n",
    "            training are used.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 x_val, \n",
    "                 y_val, \n",
    "                 min_delta=0,\n",
    "                 patience=0,\n",
    "                 verbose=0,\n",
    "                 mode='auto',\n",
    "                 baseline=None,\n",
    "                 restore_best_weights=False):\n",
    "        super(AUROCEarlyStoppingPruneCallback, self).__init__()\n",
    "\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.baseline = baseline\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_weights = None\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('EarlyStopping mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % mode,\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "        else:\n",
    "            self.monitor_op = np.greater\n",
    "\n",
    "        if self.monitor_op == np.greater:\n",
    "            self.min_delta *= 1\n",
    "        else:\n",
    "            self.min_delta *= -1\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # Allow instances to be re-used\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        if self.baseline is not None:\n",
    "            self.best = self.baseline\n",
    "        else:\n",
    "            self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = self.get_AUROC()\n",
    "        if current is None:\n",
    "            return\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(f'Epoch #{epoch}\\tValidation AUROC: {current}\\tBest AUROC: {self.best}')\n",
    "        \n",
    "\n",
    "        if self.monitor_op(current - self.min_delta, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                if self.restore_best_weights:\n",
    "                    if self.verbose > 0:\n",
    "                        print('Restoring model weights from the end of '\n",
    "                              'the best epoch')\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
    "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "    \n",
    "    # Evaluation on custom metric\n",
    "    def get_AUROC(self):\n",
    "        x_pred = self.model.predict(self.x_val, verbose=0)\n",
    "        sse = np.mean(abs(self.x_val - x_pred), axis=1)\n",
    "        fpr, tpr, thresholds = roc_curve(self.y_val, sse)\n",
    "        return auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f153ad2c-3457-4e50-9353-a9c37a120b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'NF-UNSW-NB15-V2' : './NF-UNSW-NB15-V2.parquet',\n",
    "}\n",
    "\n",
    "features_to_remove = ['L4_SRC_PORT', 'L4_DST_PORT', 'Attack', 'Label']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train = {}\n",
    "x_val = {}\n",
    "x_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0378300-646c-484a-bf2d-8e51d65ab72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NF-UNSW-NB15-V2\n",
      "====================\n",
      "\n",
      "\n",
      "Finished processing data sources.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in datasets.items():\n",
    "    print(f'Processing {key}')\n",
    "    print('='*20 + '\\n')\n",
    "    df = pd.read_parquet(value)\n",
    "    Y = df.Label\n",
    "    X_train, X_test, y_train, y_val = train_test_split(df, Y, test_size=0.3,stratify=df.Attack, random_state=42)\n",
    "    del df\n",
    "    del Y\n",
    "    gc.collect()\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, X_test.Label, test_size=0.15, stratify=X_test.Attack, random_state=42)\n",
    "    X_train = X_train[X_train.Label==0].drop(columns=features_to_remove, axis=1)\n",
    "    X_val.drop(columns=features_to_remove, axis=1, inplace=True)\n",
    "    X_test.drop(columns=features_to_remove, axis=1, inplace=True)\n",
    "    x_train[key] = scaler.fit_transform(X_train)\n",
    "    x_val[key] = (scaler.transform(X_val), y_val)\n",
    "    x_test[key] = (scaler.transform(X_test), y_test)\n",
    "    del X_train\n",
    "    del X_val\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "print()\n",
    "print('Finished processing data sources.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "071b8600-e362-46d8-b10a-104608cbda12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and testing for NF-UNSW-NB15-V2:\n",
      "============================================================\n",
      "\n",
      "Evaluation on NF-UNSW-NB15-V2:\n",
      "\n",
      "[[3.81679389e-02 4.08163265e-03 3.44502217e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.81679389e-02 0.00000000e+00 4.42060367e-05 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.81679389e-02 0.00000000e+00 4.11989176e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.81679389e-02 4.08163265e-03 1.73221147e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 6.91842900e-01]\n",
      " [3.81679389e-02 0.00000000e+00 4.09771945e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.81679389e-02 0.00000000e+00 3.80947946e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "\tUSING ROC-CURVE:\n",
      "\t\tAccuracy=0.9815220795490135\n",
      "\t\tPrecision=0.6851812138108514\n",
      "\t\tRecall=0.945546019532406\n",
      "\n",
      "\tUSING PR-CURVE and DISTANCE:\n",
      "\t\tAccuracy=0.983982819560646\n",
      "\t\tPrecision=0.7263427109974424\n",
      "\t\tRecall=0.9245338857650193\n",
      "\n",
      "\tUSING PR-CURVE and F1:\n",
      "\t\tAccuracy=0.9622052704576977\n",
      "\t\tPrecision=0.0\n",
      "\t\tRecall=0.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65857/3312364637.py:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*precision*recall)/(precision+recall)\n",
      "/home/nexei/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def create_generic_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(39,)))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(24, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(24, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(39, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Function for fitting the model on the training data, and perform intra- and inter-dataset evaluation.\n",
    "\n",
    "'''\n",
    "def fit_and_test_model(model, name):\n",
    "\n",
    "    print(f'Fitting and testing for {name}:')\n",
    "    print('='*60 + '\\n')\n",
    "    \n",
    "    #Train the model, using only the training data originating from the specific dataset.\n",
    "    history = model.fit(\n",
    "            x_train[name],\n",
    "            x_train[name],\n",
    "            epochs=15,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "            callbacks=[\n",
    "                AUROCEarlyStoppingPruneCallback(\n",
    "                        x_val[name][0], \n",
    "                        x_val[name][1],\n",
    "                        min_delta=0.0001,\n",
    "                        patience=5,\n",
    "                        mode='max',\n",
    "                        restore_best_weights=True,\n",
    "                        verbose=0\n",
    "                )\n",
    "            ]\n",
    "\n",
    "    )\n",
    "    \n",
    "    #Evaluation of the model on the test sets of ALL datasets\n",
    "    \n",
    "    for test_name in datasets.keys():\n",
    "        print(f'Evaluation on {test_name}:\\n')\n",
    "        \n",
    "        # Predictions and losses\n",
    "        val_predictions = model.predict(x_val[test_name][0], verbose=0)\n",
    "        test_predictions =  model.predict(x_test[test_name][0], verbose=0)\n",
    "        val_mae = np.mean(abs(x_val[test_name][0] - val_predictions), axis=1)\n",
    "        print(x_val[test_name][0])\n",
    "        test_mae = np.mean(abs(x_test[test_name][0]-test_predictions), axis=1)\n",
    "    \n",
    "        #Evaluate model using roc-curve and the Youden J statistic\n",
    "        fpr, tpr, thresholds = roc_curve(x_val[test_name][1], val_mae)\n",
    "        J = tpr - fpr\n",
    "        result = test_mae > thresholds[J.argmax()]\n",
    "        print('\\tUSING ROC-CURVE:')\n",
    "        print(f'\\t\\tAccuracy={accuracy_score(x_test[test_name][1], result)}\\n\\t\\tPrecision={precision_score(x_test[test_name][1], result)}\\n\\t\\tRecall={recall_score(x_test[test_name][1], result)}\\n')\n",
    "\n",
    "        #Evaluate model using precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(x_val[test_name][1], val_mae)\n",
    "            #The Euclidean distance between each point on the curve and the upper right point (1,1) (=the ideal point)\n",
    "        distance = np.sqrt((1-precision)**2 + (1-recall)**2)\n",
    "            #The F1-score\n",
    "        f1 = (2*precision*recall)/(precision+recall)\n",
    "        \n",
    "        print('\\tUSING PR-CURVE and DISTANCE:')\n",
    "        result = test_mae > thresholds[distance.argmin()]\n",
    "        print(f'\\t\\tAccuracy={accuracy_score(x_test[test_name][1], result)}\\n\\t\\tPrecision={precision_score(x_test[test_name][1], result)}\\n\\t\\tRecall={recall_score(x_test[test_name][1], result)}\\n')\n",
    "        \n",
    "        print('\\tUSING PR-CURVE and F1:')\n",
    "        result = test_mae > thresholds[f1.argmax()]\n",
    "        print(f'\\t\\tAccuracy={accuracy_score(x_test[test_name][1], result)}\\n\\t\\tPrecision={precision_score(x_test[test_name][1], result)}\\n\\t\\tRecall={recall_score(x_test[test_name][1], result)}\\n')\n",
    "        print()\n",
    "\n",
    "    \n",
    "#Fit and test UNSW\n",
    "fit_and_test_model(create_generic_model(), 'NF-UNSW-NB15-V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7396bc50-29e9-4819-b3fa-a62bb5ff20a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338166, 39)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['NF-UNSW-NB15-V2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743eabef-f75e-42e1-9cad-827b94dd3ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
