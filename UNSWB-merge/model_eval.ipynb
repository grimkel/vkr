{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3445e28-c06e-40b1-ad84-ce7e12b3398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pyarrow import csv\n",
    "import pyarrow as pa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import auc, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pyarrow import csv\n",
    "import pyarrow as pa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2bc0e05-fcd4-44a3-8b04-ea8bbb9d6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, scaler=None, useScaler=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    Y = df.Label\n",
    "    df = df.drop(['Unnamed: 0', 'Label'], axis=1)\n",
    "\n",
    "    df['Attack'] = df['Attack'].astype(\"string\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.3,stratify=df.Attack, random_state=42)\n",
    "    del df\n",
    "    del Y\n",
    "\n",
    "    attack_train = X_train['Attack']\n",
    "    X_train = X_train.drop('Attack', axis=1)\n",
    "    attack_test = X_test['Attack']\n",
    "    X_test = X_test.drop('Attack', axis=1)\n",
    "\n",
    "    X_train = X_train.drop(['SimillarHTTP'], axis=1)\n",
    "    X_train[X_train['Flow Bytes/s'] == np.inf] = 0\n",
    "    X_train[X_train[' Flow Packets/s'] == np.inf] = 0\n",
    "\n",
    "    X_test = X_test.drop(['SimillarHTTP'], axis=1)\n",
    "    X_test[X_test['Flow Bytes/s'] == np.inf] = 0\n",
    "    X_test[X_test[' Flow Packets/s'] == np.inf] = 0\n",
    "\n",
    "    \n",
    "    if useScaler:\n",
    "        X_train = scaler.transform(X_train)\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test, attack_train, attack_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061cde57-9300-4cb3-8de2-4325b5382eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200748/3331398274.py:2: DtypeWarning: Columns (62,109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, attack_train, attack_test, scaler = get_data('triple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60562a8-5f76-4b85-b9f3-3f1e97b694e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scaler.pckl)' was not found in history, as a file, url, nor in the user namespace.\n"
     ]
    }
   ],
   "source": [
    "save(scaler, \"scaler.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e372267-c2a2-4f52-8826-af82e9e3a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "class modelDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(modelDNN, self).__init__()        \n",
    "        self.layer_1 = nn.Linear(111, 4096) \n",
    "        self.layer_2 = nn.Linear(4096, 2048)\n",
    "        self.layer_3 = nn.Linear(2048, 64) \n",
    "        self.layer_4 = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(4096)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(2048)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_4(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def binary_acc(y_pred, y_test):\n",
    "    print(y_pred)\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    print(y_pred_tag)\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    print(correct_results_sum)\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    print(acc)\n",
    "    acc *= 100\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610edf19-231b-4f41-a5fd-48b918f21913",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95da2968-0d5d-4fef-8fb0-510ad57ba702",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_data = TestData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f16ef20-2341-4ab7-a176-3c91043f2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelDNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041ee6c-0a81-40d1-999d-d1b83713bfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a4cb19-3b53-450a-84c9-b1f9ca99cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b746ff-95ff-4751-bc45-80dc0b1d700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "train_loader = DataLoader(dataset=train_data, batch_size=512, shuffle=True)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa02ede-13ac-41ec-ac1b-e6e76eb201a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, attack_train, attack_test, scaler, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3058bb0-08e4-4cbe-9f3f-f763ec4e1e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_0\n",
      "y_pred_1\n",
      "y_pred_2\n",
      "y_pred_3\n",
      "y_pred_4\n",
      "y_pred_5\n",
      "y_pred_6\n",
      "y_pred_7\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(\"y_pred_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab357cdb-8257-4f94-b6a4-7425b4b2f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(data, filename):\n",
    "    file = open(filename, 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82986232-de23-4d65-a120-75cc6db37a0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.429\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.448\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.432\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.445\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.511\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.442\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.484\n",
      "Epoch 000: | Loss: 0.02032 | Train Acc: 99.349 | Test Acc: 99.441\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.475\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.477\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.461\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.468\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.530\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.463\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.493\n",
      "Epoch 001: | Loss: 0.01861 | Train Acc: 99.389 | Test Acc: 99.458\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.467\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.470\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.437\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.466\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.519\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.449\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.495\n",
      "Epoch 002: | Loss: 0.01573 | Train Acc: 99.494 | Test Acc: 99.441\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.459\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.476\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.459\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.467\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.533\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.467\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.491\n",
      "Epoch 003: | Loss: 0.01521 | Train Acc: 99.508 | Test Acc: 99.458\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.492\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.501\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.490\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.505\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.545\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.476\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.520\n",
      "Epoch 004: | Loss: 0.01485 | Train Acc: 99.515 | Test Acc: 99.467\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.472\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.471\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.471\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.465\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.543\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.469\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.506\n",
      "Epoch 005: | Loss: 0.01498 | Train Acc: 99.510 | Test Acc: 99.454\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.503\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.509\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.497\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.527\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.570\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.494\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.539\n",
      "Epoch 006: | Loss: 0.01463 | Train Acc: 99.519 | Test Acc: 99.480\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.483\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.514\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.488\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.523\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.557\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.483\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.548\n",
      "Epoch 007: | Loss: 0.01445 | Train Acc: 99.525 | Test Acc: 99.474\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.479\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.481\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.466\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.489\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.523\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.475\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.503\n",
      "Epoch 008: | Loss: 0.01432 | Train Acc: 99.534 | Test Acc: 99.480\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.376\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.414\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.395\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.410\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.461\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.390\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.442\n",
      "Epoch 009: | Loss: 0.01427 | Train Acc: 99.534 | Test Acc: 99.383\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.506\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.532\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.513\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.540\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.569\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.513\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.559\n",
      "Epoch 010: | Loss: 0.01412 | Train Acc: 99.534 | Test Acc: 99.478\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.413\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.447\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.422\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.438\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.486\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.425\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.480\n",
      "Epoch 011: | Loss: 0.01392 | Train Acc: 99.538 | Test Acc: 99.394\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.437\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.475\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.455\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.463\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.521\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.468\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.498\n",
      "Epoch 012: | Loss: 0.01389 | Train Acc: 99.538 | Test Acc: 99.461\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.483\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.492\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.461\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.489\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.524\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.475\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.516\n",
      "Epoch 013: | Loss: 0.01386 | Train Acc: 99.538 | Test Acc: 99.458\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.478\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.482\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.467\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.504\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.529\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.464\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.531\n",
      "Epoch 014: | Loss: 0.01372 | Train Acc: 99.541 | Test Acc: 99.430\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.512\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.503\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.485\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.509\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.563\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.501\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.538\n",
      "Epoch 015: | Loss: 0.01358 | Train Acc: 99.550 | Test Acc: 99.452\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.481\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.504\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.485\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.524\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.538\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.483\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.533\n",
      "Epoch 016: | Loss: 0.01355 | Train Acc: 99.546 | Test Acc: 99.461\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.487\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.493\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.510\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.529\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.562\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.508\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.541\n",
      "Epoch 017: | Loss: 0.01350 | Train Acc: 99.543 | Test Acc: 99.456\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.470\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.487\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.465\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.509\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.525\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.473\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.519\n",
      "Epoch 018: | Loss: 0.01344 | Train Acc: 99.547 | Test Acc: 99.461\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.449\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.475\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.472\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.507\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.536\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.461\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.530\n",
      "Epoch 019: | Loss: 0.01341 | Train Acc: 99.543 | Test Acc: 99.448\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(8):\n",
    "        del y_pred\n",
    "        y_pred = model(torch.Tensor(X_test[i*100000 : min(i*100000 + 100000, X_test.shape[0])]).to(device))\n",
    "        save(y_pred, \"y_pred_\"+str(i))\n",
    "        test_acc = binary_acc(y_pred, torch.Tensor(np.array(y_test[i*100000 : min(i*100000 + 100000, y_test.shape[0])])).to(device).unsqueeze(1)) \n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Train Acc: {epoch_acc/len(train_loader):.3f} | Test Acc: {test_acc:.3f}')\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd53910-7280-4987-9872-72d2248bae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(y_test, \"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe8c27-c1f9-4b4d-b755-a5a4eb1941cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"new-KNN.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee8def0e-dc34-4e1c-8fb7-41a69be794d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(preds):\n",
    "    t = torch.round(torch.sigmoid(y_pred)).cpu().detach().numpy().reshape(-1)\n",
    "    c1 = str(int(np.sum(t == 1 )))\n",
    "    c0 = str(int(np.sum(t == 0 )))\n",
    "    #print(\"1: \"+ c1 + \"| 2: \"+ c2)\n",
    "    return c1, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ef2c624-aed4-4172-a59d-bba2ac03a920",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24154/3985605892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "get_count(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27968e18-8b74-430d-b7a9-f35c84e7504f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b50bb-4b11-4d26-89cb-8261fea28de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cae46-5a73-4aba-98ee-b47a484feeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8875871-802e-4f60-85f7-105819b1d6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d8735-2196-451f-afe1-0d218a674670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc609c25-5d2e-4c60-acf8-49b59106f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70a120dd-49a5-4773-8f6a-6534531b5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2c2463a-60c5-4b6e-a6b8-24b67e793072",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_test.data', 'wb')\n",
    "pickle.dump(X_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70f97ecf-e36e-4678-b651-a6e7e93771f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('y_test.data', 'wb')\n",
    "pickle.dump(y_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be8e4af4-d18b-40ef-b53d-5a21595a1d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1856763    0\n",
       "712274     0\n",
       "1483074    0\n",
       "101751     0\n",
       "1853696    0\n",
       "          ..\n",
       "2442436    0\n",
       "1149877    0\n",
       "675851     0\n",
       "876316     0\n",
       "1791289    0\n",
       "Name: Label, Length: 746167, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f642f025-5ae1-403d-86ff-524d2167e26e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10317/2355735933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea8ce7d0-0e28-445b-8466-19a26b139459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.08838295, 0.15467489,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.08838295, 0.15467489,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.1767659 , 0.13257847,\n",
       "        0.5       ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.11047869, 0.08838565,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.15467017, 0.1767713 ,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0d1d0-7418-4062-ac8b-05a2ab41a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a64bb6-d1db-4e7c-8cb3-2d0d6a1d2f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c99330-49df-4040-8bd5-24477bb77cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tabularCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tabularCNN, self).__init__()\n",
    "        self.dense_1 = nn.Linear(111, 1024)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm_2_1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.dense_repl = nn.Linear(1024, 8*6*6)\n",
    "        self.batchnorm_repl = nn.BatchNorm1d(8*6*6)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv_1 = nn.Conv2d(1, 4, 3)\n",
    "        self.conv_2 = nn.Conv2d(4, 8, 3)\n",
    "        self.conv_3 = nn.Conv2d(8, 16, 3, stride=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.dense_2_1 = nn.Linear(8*6*6, 256)\n",
    "        self.dense_2_2 = nn.Linear(256, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.dense_1(inputs))\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(self.dense_repl(x))\n",
    "        x = self.batchnorm_repl(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #x = x.reshape(len(x), 1, 32, 32)\n",
    "        #x = self.pool(self.relu(self.conv_1(x)))\n",
    "        #x = self.pool(self.relu(self.conv_2(x)))\n",
    "\n",
    "        #x = x.reshape(len(x), 8*6*6)\n",
    "        \n",
    "        x = self.relu(self.dense_2_1(x))\n",
    "        x = self.batchnorm_2_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(self.dense_2_2(x))    \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a68f311-8c08-4476-9e00-dd1fc52d9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tabularCNN().to(device)\n",
    "miodel = modelDNN().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "        \n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16384, shuffle=True)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "696a43cb-a494-405b-99cb-47ed5c39a6d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_200748/1063701837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred.shape[0] / X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f73739c-276d-4e24-949d-15cb4fbe7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.7907],\n",
      "        [-9.1293],\n",
      "        [-7.8146],\n",
      "        ...,\n",
      "        [-8.6820],\n",
      "        [-7.5472],\n",
      "        [-8.1677]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16302., device='cuda:0')\n",
      "tensor(0.9950, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-7.7492],\n",
      "        [21.8608],\n",
      "        [-8.3170],\n",
      "        ...,\n",
      "        [-8.0722],\n",
      "        [-9.2845],\n",
      "        [-8.7691]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16290., device='cuda:0')\n",
      "tensor(0.9943, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-7.7287],\n",
      "        [-6.4698],\n",
      "        [-9.1703],\n",
      "        ...,\n",
      "        [26.0610],\n",
      "        [-7.7646],\n",
      "        [25.1712]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16301., device='cuda:0')\n",
      "tensor(0.9949, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-8.4669],\n",
      "        [-7.4844],\n",
      "        [-7.8529],\n",
      "        ...,\n",
      "        [22.6361],\n",
      "        [-9.0144],\n",
      "        [-9.2480]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16296., device='cuda:0')\n",
      "tensor(0.9946, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-7.8367],\n",
      "        [-7.8740],\n",
      "        [ 2.4729],\n",
      "        ...,\n",
      "        [-8.6408],\n",
      "        [-8.3245],\n",
      "        [-0.5083]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16303., device='cuda:0')\n",
      "tensor(0.9951, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-6.4061],\n",
      "        [-8.3093],\n",
      "        [21.4319],\n",
      "        ...,\n",
      "        [-8.4016],\n",
      "        [-8.0936],\n",
      "        [-9.3516]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16294., device='cuda:0')\n",
      "tensor(0.9945, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-8.1785],\n",
      "        [ 3.8706],\n",
      "        [-7.9565],\n",
      "        ...,\n",
      "        [-8.2678],\n",
      "        [-5.0518],\n",
      "        [-7.7892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16321., device='cuda:0')\n",
      "tensor(0.9962, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-8.1484],\n",
      "        [24.7562],\n",
      "        [-8.0806],\n",
      "        ...,\n",
      "        [-9.3394],\n",
      "        [ 3.8573],\n",
      "        [-7.8500]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16304., device='cuda:0')\n",
      "tensor(0.9951, device='cuda:0')\n",
      "---------------------------------\n",
      "tensor([[-8.8200],\n",
      "        [23.6854],\n",
      "        [22.0911],\n",
      "        ...,\n",
      "        [-9.4679],\n",
      "        [-9.3549],\n",
      "        [-7.6440]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)\n",
      "tensor(16299., device='cuda:0')\n",
      "tensor(0.9948, device='cuda:0')\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_200748/1619150230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_200748/1729582440.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    model.eval()\n",
    "    \n",
    "    test_acc = 0\n",
    "    for i in range(75):\n",
    "        del y_pred\n",
    "        y_pred = model(torch.Tensor(X_test[i*10000 : min(i*10000 + 10000, X_test.shape[0])]).to(device))\n",
    "        c0, c1 = get_count(y_pred)\n",
    "        test_acc += binary_acc(y_pred, torch.Tensor(np.array(y_test[i*10000 : min(i*10000 + 10000, y_test.shape[0])])).to(device).unsqueeze(1)) * (y_pred.shape[0] / X_test.shape[0])\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Train Acc: {epoch_acc/len(train_loader):.3f} | Test Acc: {test_acc:.3f}')\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7172e93d-7e14-4dd7-8dd6-507044a40de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabularCNN(\n",
       "  (dense_1): Linear(in_features=111, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batchnorm_1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_1): Conv2d(1, 4, kernel_size=(5, 5), stride=(6, 6))\n",
       "  (relu): ReLU()\n",
       "  (dense_2): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2a71f4-0835-4ca3-a468-8d257a2b7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"TabularCNN.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e624df-e58e-4800-831a-e49eeb8767c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b6900ee-c96c-47f6-87a9-3599c760e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(20, 16, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41553a3c-6c4a-49a4-a5fc-94f32184de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv2d(16, 33, 3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66a5f239-a8a1-4236-811c-4bbbd297a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11fd6ebd-4d38-445d-9163-99d6a031c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 24, 49])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96fc19-0220-464b-b709-da05439a8f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
