{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3445e28-c06e-40b1-ad84-ce7e12b3398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pyarrow import csv\n",
    "import pyarrow as pa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import auc, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pyarrow import csv\n",
    "import pyarrow as pa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2bc0e05-fcd4-44a3-8b04-ea8bbb9d6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, scaler=None, useScaler=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    Y = df.Label\n",
    "    df = df.drop(['Unnamed: 0', 'Label'], axis=1)\n",
    "\n",
    "    df['Attack'] = df['Attack'].astype(\"string\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.3,stratify=df.Attack, random_state=42)\n",
    "    del df\n",
    "    del Y\n",
    "\n",
    "    attack_train = X_train['Attack']\n",
    "    X_train = X_train.drop('Attack', axis=1)\n",
    "    attack_test = X_test['Attack']\n",
    "    X_test = X_test.drop('Attack', axis=1)\n",
    "\n",
    "    X_train = X_train.drop(['SimillarHTTP'], axis=1)\n",
    "    X_train[X_train['Flow Bytes/s'] == np.inf] = 0\n",
    "    X_train[X_train[' Flow Packets/s'] == np.inf] = 0\n",
    "\n",
    "    X_test = X_test.drop(['SimillarHTTP'], axis=1)\n",
    "    X_test[X_test['Flow Bytes/s'] == np.inf] = 0\n",
    "    X_test[X_test[' Flow Packets/s'] == np.inf] = 0\n",
    "\n",
    "    \n",
    "    if useScaler:\n",
    "        X_train = scaler.transform(X_train)\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test, attack_train, attack_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061cde57-9300-4cb3-8de2-4325b5382eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7073/3331398274.py:2: DtypeWarning: Columns (62,109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, attack_train, attack_test, scaler = get_data('triple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60562a8-5f76-4b85-b9f3-3f1e97b694e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scaler.pckl)' was not found in history, as a file, url, nor in the user namespace.\n"
     ]
    }
   ],
   "source": [
    "save(scaler, \"scaler.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e372267-c2a2-4f52-8826-af82e9e3a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "class modelDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(modelDNN, self).__init__()        \n",
    "        self.layer_1 = nn.Linear(111, 4096) \n",
    "        self.layer_2 = nn.Linear(4096, 2048)\n",
    "        self.layer_3 = nn.Linear(2048, 64) \n",
    "        self.layer_4 = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(4096)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(2048)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_4(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc *= 100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610edf19-231b-4f41-a5fd-48b918f21913",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95da2968-0d5d-4fef-8fb0-510ad57ba702",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_data = TestData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde20e01-b6a3-432a-94e5-e08636086242",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelDNN().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b746ff-95ff-4751-bc45-80dc0b1d700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "train_loader = DataLoader(dataset=train_data, batch_size=512, shuffle=True)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa02ede-13ac-41ec-ac1b-e6e76eb201a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, attack_train, attack_test, scaler, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3058bb0-08e4-4cbe-9f3f-f763ec4e1e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_0\n",
      "y_pred_1\n",
      "y_pred_2\n",
      "y_pred_3\n",
      "y_pred_4\n",
      "y_pred_5\n",
      "y_pred_6\n",
      "y_pred_7\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(\"y_pred_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab357cdb-8257-4f94-b6a4-7425b4b2f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(data, filename):\n",
    "    file = open(filename, 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82986232-de23-4d65-a120-75cc6db37a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.480\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.489\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.486\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.512\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.549\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.477\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.514\n",
      "Epoch 000: | Loss: 0.02031 | Train Acc: 99.333 | Test Acc: 99.445\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.448\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.468\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.450\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.482\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.522\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.458\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.484\n",
      "Epoch 001: | Loss: 0.01598 | Train Acc: 99.484 | Test Acc: 99.404\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.511\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.510\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.495\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.540\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.581\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.509\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.552\n",
      "Epoch 002: | Loss: 0.01535 | Train Acc: 99.502 | Test Acc: 99.493\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.484\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.482\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.487\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.495\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.563\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.493\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.506\n",
      "Epoch 003: | Loss: 0.01554 | Train Acc: 99.487 | Test Acc: 99.487\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7073/1694390369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(8):\n",
    "        del y_pred\n",
    "        y_pred = model(torch.Tensor(X_test[i*100000 : min(i*100000 + 100000, X_test.shape[0])]).to(device))\n",
    "        save(y_pred, \"y_pred_\"+str(i))\n",
    "        test_acc = binary_acc(y_pred, torch.Tensor(np.array(y_test[i*100000 : min(i*100000 + 100000, y_test.shape[0])])).to(device).unsqueeze(1)) \n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Train Acc: {epoch_acc/len(train_loader):.3f} | Test Acc: {test_acc:.3f}')\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd53910-7280-4987-9872-72d2248bae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(y_test, \"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5afe8c27-c1f9-4b4d-b755-a5a4eb1941cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"new-KNN.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee8def0e-dc34-4e1c-8fb7-41a69be794d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ef2c624-aed4-4172-a59d-bba2ac03a920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27968e18-8b74-430d-b7a9-f35c84e7504f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b50bb-4b11-4d26-89cb-8261fea28de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cae46-5a73-4aba-98ee-b47a484feeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8875871-802e-4f60-85f7-105819b1d6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d8735-2196-451f-afe1-0d218a674670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc609c25-5d2e-4c60-acf8-49b59106f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70a120dd-49a5-4773-8f6a-6534531b5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2c2463a-60c5-4b6e-a6b8-24b67e793072",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_test.data', 'wb')\n",
    "pickle.dump(X_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70f97ecf-e36e-4678-b651-a6e7e93771f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('y_test.data', 'wb')\n",
    "pickle.dump(y_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be8e4af4-d18b-40ef-b53d-5a21595a1d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1856763    0\n",
       "712274     0\n",
       "1483074    0\n",
       "101751     0\n",
       "1853696    0\n",
       "          ..\n",
       "2442436    0\n",
       "1149877    0\n",
       "675851     0\n",
       "876316     0\n",
       "1791289    0\n",
       "Name: Label, Length: 746167, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f642f025-5ae1-403d-86ff-524d2167e26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelDNN(\n",
       "  (layer_1): Linear(in_features=111, out_features=4096, bias=True)\n",
       "  (layer_2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (layer_3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (layer_4): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batchnorm1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea8ce7d0-0e28-445b-8466-19a26b139459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.08838295, 0.15467489,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.08838295, 0.15467489,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.1767659 , 0.13257847,\n",
       "        0.5       ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.11047869, 0.08838565,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.15467017, 0.1767713 ,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0d1d0-7418-4062-ac8b-05a2ab41a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a64bb6-d1db-4e7c-8cb3-2d0d6a1d2f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06c99330-49df-4040-8bd5-24477bb77cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tabularCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tabularCNN, self).__init__()\n",
    "        self.dense_1 = nn.Linear(111, 1024)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(64, 32, 5)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.dense_2 = nn.Linear(2048, 1024)\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(1024)\n",
    "        self.dense_3 = nn.Linear(1024, 128)\n",
    "        self.batchnorm_3 = nn.BatchNorm1d(128)\n",
    "        self.dense_4 = nn.Linear(128, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.dense_1(inputs))\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x.reshape(len(x), 64, 16)\n",
    "        x = self.relu(self.conv_1(x))\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        x = x.reshape(len(x), 2048)\n",
    "        x = self.relu(self.dense_2(x))\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.dense_3(x))\n",
    "        x = self.batchnorm_3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.dense_4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac829b8b-57f6-4a3e-9872-c10a5397cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tabularCNN().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "        \n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16384, shuffle=True)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f73739c-276d-4e24-949d-15cb4fbe7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384, 32, 12])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16384, 2048]' is invalid for input of size 6291456",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24154/2251938660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24154/1059110210.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16384, 2048]' is invalid for input of size 6291456"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(80):\n",
    "        del y_pred\n",
    "        y_pred = model(torch.Tensor(X_test[i*10000 : min(i*10000 + 10000, X_test.shape[0])]).to(device))\n",
    "        save(y_pred, \"y_pred_\"+str(e)+\"+\"+str(i))\n",
    "        test_acc = binary_acc(y_pred, torch.Tensor(np.array(y_test[i*10000 : min(i*10000 + 10000, y_test.shape[0])])).to(device).unsqueeze(1)) \n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Train Acc: {epoch_acc/len(train_loader):.3f} | Test Acc: {test_acc:.3f}')\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7172e93d-7e14-4dd7-8dd6-507044a40de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelDNN(\n",
       "  (layer_1): Linear(in_features=111, out_features=4096, bias=True)\n",
       "  (layer_2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (layer_3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (layer_4): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batchnorm1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2a71f4-0835-4ca3-a468-8d257a2b7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"TabularCNN.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e624df-e58e-4800-831a-e49eeb8767c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6900ee-c96c-47f6-87a9-3599c760e78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
